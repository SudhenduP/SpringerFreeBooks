import os
import requests
from urllib.parse import urljoin
from bs4 import BeautifulSoup as bs
import re


#file_path=r'C:\Users\Sudhendu-BCT\Documents\Projects\self\spingerbooks\url.txt'
#folder_location= r'C:\Users\Sudhendu-BCT\Documents\Projects\self\spingerbooks'

print("Enter the txt file path: ")
file_path=input()

If there is no such folder, the script will create one automatically
print("Enter a folder path: ")
folder_location=input()

if not os.path.exists(folder_location):os.mkdir(folder_location)

with open(file_path, encoding='UTF-8') as file:
        for line in file:
            urls = re.findall('(https?://[^\s]+)', line)
            if urls !=[]:
                final_url=urls
                r = requests.get(final_url[0])
                redirect_url= r.url
                book_id=r.url.rsplit("/",1)[1]
                print(book_id)
                soup = bs(r.content, 'lxml')
                print(soup.select_one('title').text)
                page_title= soup.select_one('title').text
                page_title_file_name=page_title.rsplit(" |",1)[0].replace(" ", "_")+'.pdf'
                filename = os.path.join(folder_location,page_title_file_name)
                #print(filename)
                with open(filename, 'wb') as f:
                    print(urljoin("https://link.springer.com/content/pdf/",book_id))
                    f.write(requests.get(urljoin("https://link.springer.com/content/pdf/",book_id,'.pdf')).content)
                    print("Enjoy reading the " +filename, " . It is downloaded successfully!!!")
