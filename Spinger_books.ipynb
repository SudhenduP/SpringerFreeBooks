import os
import requests
from urllib.parse import urljoin
from bs4 import BeautifulSoup as bs
import re



#print("Enter the text file path: ")
#file_path=input()

file_path=r'C:\Users\Sudhendu-BCT\Documents\Projects\self\spingerbooks\url.txt'
folder_location= r'C:\Users\Sudhendu-BCT\Documents\Projects\self\spingerbooks'

#If there is no such folder, the script will create one automatically
#print("Enter a folder path: ")
#folder_location=input()

#folder_location = r'C:\Users\Sudhendu-BCT\Documents\Projects\self\Mobility'
if not os.path.exists(folder_location):os.mkdir(folder_location)

with open(file_path, encoding='UTF-8') as file:
        for line in file:
            urls = re.findall('(https?://[^\s]+)', line)
            if urls !=[]:
                final_url=urls
                r = requests.get(final_url[0])
                redirect_url= r.url
                book_id=r.url.rsplit("/",1)[1]
                print(book_id)
                soup = bs(r.content, 'lxml')
                print(soup.select_one('title').text)
                page_title= soup.select_one('title').text
                page_title_file_name=page_title.rsplit(" |",1)[0].replace(" ", "_")+'.pdf'
                filename = os.path.join(folder_location,page_title_file_name)
                #print(filename)
                with open(filename, 'wb') as f:
                    print(urljoin("https://link.springer.com/content/pdf/",book_id))
                    f.write(requests.get(urljoin("https://link.springer.com/content/pdf/",book_id,'.pdf')).content)
                    print("File Written")
